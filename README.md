<!-- PROJECT LOGO -->
<br />
<div align="center">
  <a href="https://github.com/Lakusan/invisnav">
    <img src="README_assets/invisnav_icon.png" alt="Logo" width="80" height="80">
  </a>

<h3 align="center">
<span style="color: #84cc16;">IN</span>
    <span style="color: #f59e0b;">VIS</span>
    <span style="color: #8b5cf6;">NAV</span></h3>

  <p align="center">
    <br />
    <span style="color: #84cc16;">Indoor</span>
    <span style="color: #f59e0b;">Visual</span>
    <span style="color: #8b5cf6;">Navigation</span>
    </br>
    </br>
    <a href="https://github.com/Lakusan/invisnav/blob/develop/MA_Thesis_Andreas_Lakus.pdf"><strong>Read Thesis »</strong></a>
    <br />
    <br />
    <a href="https://github.com/Lakusan/invisnav/blob/main/Kolloquium_Master_Thesis.pdf"><strong>View Presentaion »</strong></a>
</div>


<!-- ABOUT THE PROJECT -->
## About The Project
<div>
    </br>
    <p>
   This application was developed as part of my Master's thesis in Applied Computer Science at SRH University Heidelberg, from March to September 2024.
    </p>
    <p>
    Abstract:
    </p>
    <p>
        Indoor navigation systems often require a digital map of the building and integrated guidance
        sensors as the infrastructure components. Therefore, indoor navigation is only possible if the
        prerequisites are met. If navigation is required in an unknown room, solutions from the field
        of Simultaneous Localization and Mapping (SLAM) are often used. SLAM addresses the
        problem of an autonomous system trying to localize itself in unknown terrain using its own
        sensors. If images generated by cameras are combined with computer vision techniques, this
        allows the generation of an environment map during runtime. In this work, a prototype of a
        visual positioning system for solving the SLAM problem using cameras, based on the Unity
        Engine and ARCore, is presented. The prototype demonstrates the scanning capabilities of
        ARCore through spatial reconstruction as a digital twin for navigation to self-defined targets.
        Furthermore, it is demonstrated that reconstruction based on minimal data sets is possible.
        Collaborative use is ensured by publishing the map data in a cloud database.
    </p>
</div>

<section style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px; text-align: start;">
    <div style="color: white; padding: 10px; width: 95%; height: 96%; margin: 0;">
        <img src="README_assets/screenshot_1.jpg" alt="Screenshot1" width="300" height="600" style="display: block;"></img>
    </div>
    <div style="color: white; padding: 10px; width: 95%; height: 96%; margin: 0;">
        <h3>Scanning</h3>
        <ul>
            <li style="padding: 5px; margin: 5px;">Real-time generation of Meshes (yellowish)</li>
            <li style="padding: 5px; margin: 5px;">Dynamic NavMesh Generation (green)</li>
            <li style="padding: 5px; margin: 5px;">Anchor Placement as Navigation Target (green cube)</li>
        </ul>
    </div>
    <div style="color: white; padding: 10px; width: 95%; height: 96%; margin: 0;">
        <img src="README_assets/screenshot_2.jpg" alt="Screenshot2" width="300" height="600" style="display: block;">
    </div>
    <div style="color: white; padding: 10px; width: 95%; height: 96%; margin: 0;">
        <h3>Navigation</h3>
        <ul>
            <li style="padding: 5px; margin: 5px;">Loadable Map as blue Map Segments</li>
            <li style="padding: 5px; margin: 5px;">Green Dummy Anchors get loaded as Navigation Targets</li>
            <li style="padding: 5px; margin: 5px;">NavMesh gets generated and path can be rentered</li>
        </ul>
    </div>
    <div style="color: white; padding: 10px; width: 95%; height: 96%; margin: 0;">
        <img src="README_assets/screenshot_3.jpg" alt="Screenshot3" width="800" height="500" style="display: block;">
    </div>
    <div style="color: white; padding: 10px; width: 95%; height: 96%; margin: 0;">
        <h3>Mapping</h3>
           <ul>
            <li style="padding: 5px; margin: 5px;">Scan Segments get added to Map, which gehts uploeaded as JSON object</li>
            <li style="padding: 5px; margin: 5px;">If Map is loaded, NavMesh gets regenerated and servers as foundation of path generation to targets</li>
        </ul>
    </div>
</section>


<!-- Dependencies -->
## Dependencies

* Unity Engine 2022.3.22f1
* AR Foundation 5.1.3
* Google ARCore XR Plugin 5.1.5
* Niantic Lightship AR Plugin 3.6.0
* Firebase Realtime


<!-- Feature Set -->
## Features

- [X] Scan Environment
  - [X] Utilization of device IMU for Map Alignment
  - [X] Create digital twin of scanned environment as Unity Mesh
  - [X] Sematic Segmentation of Scanned Point Cloud Segements to only save floor levels
  - [X] Place Virtual Anchors as Navigation Targets
  - [X] Upload constructed Map as JSON to Firebase Realtime and publish
- [X] Navigation
  - [X] Load Map from Firebase Realtime and reconstruct Environment
  - [X] (Re-)Align Map with IMU Data
  - [X] Choose Navigation Target
  - [X] Folow Path to Target


### Installation

1. Get Unity Hub
2. Download Unity Engine () and install
3. Clone this Repository
4. Start Porject - UPM Packages should install automatically
5. Setup Firebase Realtime and add Links to Project files in /scripts/DBManager

<!-- USAGE EXAMPLES -->
## Usage

This Project can be compiled for Android 12. For a different Confiuguration change build settings.
Otherwise you could stream to Unity Remote via USB.
</br>


<!-- LICENSE -->
## License

Distributed under the MIT License. See `LICENSE.txt` for more information.
</br>

<!-- CONTACT -->
## Contact

* Project Link: [https://github.com/Lakusan/invisnav](https://github.com/Lakusan/invisnav)
* [![LinkedIn][linkedin-shield]][linkedin-url]

<!-- MARKDOWN LINKS & IMAGES -->
<!-- https://www.markdownguide.org/basic-syntax/#reference-style-links -->
[issues-shield]: https://img.shields.io/github/issues/github_username/repo_name.svg?style=for-the-badge
[issues-url]: https://github.com/Lakusan/invisnav/issues
[license-shield]: https://img.shields.io/github/license/github_username/repo_name.svg?style=for-the-badge
[license-url]: https://github.com/Lakusan/invisnav/blob/master/LICENSE.txt
[linkedin-shield]: https://img.shields.io/badge/-LinkedIn-black.svg?style=for-the-badge&logo=linkedin&colorB=555
[linkedin-url]: https://www.linkedin.com/in/lakusan